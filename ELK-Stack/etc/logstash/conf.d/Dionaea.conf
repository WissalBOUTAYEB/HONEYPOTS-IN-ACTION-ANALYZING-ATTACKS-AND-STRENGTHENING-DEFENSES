
input {
  file {
    path => "/opt/dionaea/var/log/dionaea/dionaea.json"  # Path to Dionaea JSON log file
    codec => "json"  # Parse input as JSON
    start_position => "beginning"  # Start reading from the beginning of the file
    sincedb_path => "/dev/null"  # Prevents Logstash from skipping logs
    type => "dionaea"  # Tag logs as dionaea type for easy filtering
  }
}

filter {
  # Ensure only Dionaea logs are processed
  if [type] == "dionaea" {
    
    # Match general log format (timestamp, module, log level, log message)
    grok {
      match => {
        "message" => "\[%{DATESTAMP:timestamp}\] %{DATA:module} %{PATH:file}:%{NUMBER:line}-%{LOGLEVEL:level}: %{GREEDYDATA:log_message}"
      }
    }

    # Parse "reject connection" logs
    grok {
      match => {
        "log_message" => "reject connection from %{IPV4:src_ip}:%{NUMBER:src_port} to %{IPV4:dst_ip}:%{NUMBER:dst_port} \(id=%{NUMBER:attack_id})"
      }
      add_tag => ["connection", "rejected"]
    }

    # Parse "accepted connection" logs
    grok {
      match => {
        "log_message" => "accepted connection from %{IPV4:src_ip}:%{NUMBER:src_port} to %{IPV4:dst_ip}:%{NUMBER:dst_port} \(id=%{NUMBER:attack_id})"
      }
      add_tag => ["connection", "accepted"]
    }

    # GeoIP enrichment for source and destination IP addresses
    geoip {
      source => "src_ip"
      target => "geoip_src"
      fields => ["city_name", "country_name", "country_code2", "location"]
    }

    geoip {
      source => "dst_ip"
      target => "geoip_dst"
      fields => ["city_name", "country_name", "country_code2", "location"]
    }

    # Add timestamp from the log message for better processing
    mutate {
      add_field => { "event_timestamp" => "%{timestamp}" }
    }

    # Normalize port fields (ensure they are integers for easier sorting/searching)
    mutate {
      convert => {
        "src_port" => "integer"
        "dst_port" => "integer"
      }
    }

    # Update eventid to match Dionaea-specific events
    mutate {
      replace => { "eventid" => "dionaea.connection" }
    }

    # Optionally, add metadata fields
    mutate {
      add_field => {
        "[@metadata][index]" => "dionaea-logs-%{+YYYY.MM.dd}"
      }
    }

    # Remove unwanted fields if necessary
    mutate {
      remove_field => ["message", "log_message", "timestamp"]
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["http://localhost:9200"]  # Adjust if Elasticsearch is on another server
    index => "dionaea-logs-%{+YYYY.MM.dd}"  # Index logs by date
    document_id => "%{[@metadata][_id]}"  # Use the unique ID for the document
  }

  # Debug output to console for inspection
  stdout {
    codec => rubydebug
  }
}
